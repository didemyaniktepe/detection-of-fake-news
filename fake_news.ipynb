{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Fake News!\n",
    "\n",
    "Hacettepe University\n",
    "\n",
    "BBM 409\n",
    "\n",
    "Machine Learning Lab.\n",
    "\n",
    "Didem Yanıktepe\n",
    "\n",
    "21527563\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Theory Questions\n",
    "\n",
    "#### MLE \n",
    "\n",
    "###### 1)\n",
    "Maximum Likelihood Estimation can be applied to a vector valued parameter.For a simple random sample of n normal random variables we can use the properties of the exponential function to simplfiy the likelihood function \n",
    "<img src=\"3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "The score function \n",
    "<img src=\"4.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "Because the second partial derivative with respect to mean is negative. So mean = sum of x / n \n",
    "\n",
    "\n",
    "###### 2)\n",
    "Based on the NB conditional independence assumption the probability of observing a vector x can be compactly written\n",
    "<img src=\"7.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "In the above expression, xi is either 0 or 1 and hence each i term contributes a factor θic if xi = 1 or 1 − θic if xi = 0. Together with the assumption that the training data is i.i.d. generated, the log likelihood of the attributes and class labels is\n",
    "<img src=\"8.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "We can find the Maximum Likelihood optimal θic by differentiating w.r.t. and equating to zero, giving\n",
    "for class c number of datapoints in class c\n",
    "<img src=\"9.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "Similarly, optimising equationwith respect to p(c) gives p(c) = number of times class c occurs\n",
    "total number of data points\n",
    "<img src=\"10.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "###### 3)\n",
    "Due to fact that the sample is (3,0,2,1,3,2,..) the likelihood \n",
    "\n",
    "<img src=\"5.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "Subtituting from the probability distrubution :\n",
    "<img src=\"6.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "###### 1)\n",
    "content :(1, 1, 1), (0, 0, 1), (1, 1, 0), (1, 0, 1) and for ’not content’: (0, 0, 0), (1, 0, 0), (0, 0, 1), (0, 1, 0), (0, 0, 0) .\n",
    "P(content|0,1,1) = P(0,1,1|content)*p(content)/P(0,1,1|content)*p(content)+p(0,1,1|notcontent)*p(notcontent)\n",
    "\n",
    "P(not rich|content) = 1/4\n",
    "P(married|content) = 1/2\n",
    "P(health|content) = 3/4\n",
    "p(content) = 4/9\n",
    "\n",
    "P(not rich|notcontent) = 4/5\n",
    "P(married|notcontent) = 1/5\n",
    "P(health|notcontent) = 1/5\n",
    "p(notcontent) = 5/9\n",
    "\n",
    "\n",
    "we multiply all of them divison by P(0,1,1) = 1/24 / (1/24+4/(9*5*5) = 0.7009345794\n",
    "###### 2)\n",
    "P(content|0,1,?) = P(0,1,?|content)*P(content)\n",
    "\n",
    "P(not rich|content)= 3/4\n",
    "P(married|content) = 1/2\n",
    "P(content) = 4/9\n",
    "\n",
    "P(not rich|notcontent)= 4/5\n",
    "P(married|notcontent) = 1/5\n",
    "P(notcontent) = 5/9\n",
    "\n",
    "we multiply all of them = 4/6 / (4/6+4/45) = 0.88235294117\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II: Detection of Fake News\n",
    "<img src=\"2.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "### Dataset\n",
    "The data-set consists of real and fake news headlines related to the recent U.S elections, with about 1673 real headline and about 1104 fake headlines. By looking at the number of word occurrences we see that the words used the most for both real and fake headlines are mostly similar. We can also see that many of those words are stop-words (\"of\", \"for\", \"on\" ... etc). I have listed below three examples that I believe will help in classifying the headlines as real or fake.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake news headlines : \n",
      "\n",
      "1   trump warns of vote flipping on machines\n",
      "\n",
      "2   this election is not about trump its about a giant middle finger to washington dc\n",
      "\n",
      "3   more on trump populism and how it can be controlled by government\n",
      "\n",
      "Real news headlines : \n",
      "\n",
      "1   donald trump charlottesville comments praised by supporters\n",
      "\n",
      "2   trumps new us immigration plan to be based on australias\n",
      "\n",
      "3   trump presidency could bring range of economic disasters eslake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_news_file = open(\"clean_fake-Train.txt\",\"r\")\n",
    "real_news_file = open(\"clean_real-Train.txt\",\"r\")\n",
    "\n",
    "bifake_news_file = open(\"clean_fake-Train.txt\",\"r\")\n",
    "bireal_news_file = open(\"clean_real-Train.txt\",\"r\")\n",
    "\n",
    "\n",
    "fake_part3 = list()\n",
    "fake_news_list = list()\n",
    "fake_news_size = 0\n",
    "\n",
    "count = 0\n",
    "print(\"Fake news headlines : \\n\")\n",
    "for x in fake_news_file:\n",
    "    if(count<3):\n",
    "        print(count+1,\" \",x)\n",
    "        count+=1\n",
    "    fake_news_size += 1\n",
    "    x = x.split(\"\\n\")\n",
    "    fake_part3.append(x[0])\n",
    "    x = x[0].split(\" \")\n",
    "    for m in x:\n",
    "        fake_news_list.append(m)\n",
    "\n",
    "all_words = \"\"\n",
    "for i in fake_news_list:\n",
    "    all_words += i+\" \"\n",
    "\n",
    "fake_all_words = all_words\n",
    "fake_news_list = []\n",
    "fake_news_list.append(all_words)\n",
    "\n",
    "\n",
    "real_news_list = list()\n",
    "real_part3 = list()\n",
    "real_news_size = 0\n",
    "\n",
    "print(\"Real news headlines : \\n\")\n",
    "count = 0\n",
    "for x in real_news_file:\n",
    "    if(count<3):\n",
    "        print(count+1,\" \",x)\n",
    "        count+=1\n",
    "    real_news_size += 1\n",
    "    x = x.split(\"\\n\")\n",
    "    real_part3.append(x[0])\n",
    "    x = x[0].split(\" \")\n",
    "    for m in x:\n",
    "        real_news_list.append(m)\n",
    "\n",
    "all_words = \"\"\n",
    "\n",
    "\n",
    "for i in real_news_list:\n",
    "    all_words += i+\" \"\n",
    "\n",
    "real_all_words = all_words\n",
    "real_news_list = []\n",
    "real_news_list.append(all_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment for bag of word i use CountTokenizer library to calculate how many times the word is exist in the real and fake headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for real news\n",
      "Trump's count in bag of words : 1484\n",
      "Trump's index : 2967\n"
     ]
    }
   ],
   "source": [
    "fake_news_vec = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None)\n",
    "fake_news_train = fake_news_vec.fit(fake_news_list)\n",
    "bag_of_words_fake = fake_news_vec.transform(fake_news_list)\n",
    "\n",
    "real_news_vec = CountVectorizer(ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None)\n",
    "real_news_train = real_news_vec.fit(real_news_list)\n",
    "bag_of_words_real = real_news_vec.transform(real_news_list)\n",
    "\n",
    "print(\"Example for real news\")\n",
    "print(\"Trump's count in bag of words :\",bag_of_words_real.toarray()[0][2967])\n",
    "print(\"Trump's index : {}\".format(real_news_train.vocabulary_.get(\"trump\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Algorithm\n",
    "\n",
    "The goal of any probabilistic classifier is, with features x_0 through x_n and classes c_0 through c_k, to determine the probability of the features occurring in each class, and to return the most likely class. Therefore, for each class, we want to be able to calculate P(c_i | x_0, …, x_n).\n",
    "In order to do this, we use Bayes rule. Recall that Bayes rule is the following:\n",
    "\n",
    "<img src=\"1.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "The Naive Bayes algorithm is applied on the dataset in naive bayes.py.\n",
    "Our goal is to compute P(fake|w) given P(w|fake).\n",
    "For a test headline, assume wi = 1 if headline contains the word wi and wi = 0 otherwise. \n",
    "\n",
    "The Naive Bayes algorithm is applied on the dataset\n",
    "\n",
    "Our goal is to compute $P(fake | w)$ given $P(w | fake)$.\n",
    "\n",
    "For a test headline, assume $w_i = 1$ if headline contains the word $w_i$ and $w_i = 0$ otherwise.\n",
    "\n",
    "Then for training:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{P}(w_i = 1 | fake) &= \\frac {number\\_of\\_fake\\_headlines\\_containing\\_w_i + m\\hat{p}} {number\\_of\\_fake\\_headlines + m}\\\\\n",
    "\\hat{P}(w_i = 0 | fake) &= 1 - \\hat{P}(w_i = 1 | fake)\\\\\n",
    "\\hat{P}(w_i = 1 | real) &= \\frac {number\\_of\\_real\\_headlines\\_containing\\_w_i + m\\hat{p}} {number\\_of\\_real\\_headlines + m}\\\\\n",
    "\\hat{P}(w_i = 0 | real) &= 1 - \\hat{P}(w_i = 1 | real)\\\\\n",
    "\\hat{P}(fake) &= \\frac {number\\_of\\_fake\\_headlines} {number\\_of\\_total\\_headlines}\\\\\n",
    "\\hat{P}(real) &= 1 - \\hat{P}(fake)\\\\\n",
    "\\end{align*}\n",
    "\n",
    "For classifying:\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{P}(fake | w_1, w_2, ..., w_n) &\\propto \\hat{P}(fake) \\prod_{i=1}^n \\hat{P}(w_i | fake)\\\\\n",
    "\\hat{P}(real | w_1, w_2, ..., w_n) &\\propto \\hat{P}(real) \\prod_{i=1}^n \\hat{P}(w_i | real)\\\\\n",
    "\\hat{P}(fake | w_1, w_2, ..., w_n) &= \\frac {\\hat{P}(fake) \\prod_{i=1}^n \\hat{P}(w_i | fake)} {\\hat{P}(fake) \\prod_{i=1}^n \\hat{P}(w_i | fake) + \\hat{P}(real) \\prod_{i=1}^n \\hat{P}(w_i | real)}\n",
    "\\end{align*}\n",
    "\n",
    "If $\\hat{P}(fake | w_1, w_2, ..., w_n) >= 0.5$, the headline was classified as fake and otherwise, real.\n",
    "\n",
    "Note: since $\\prod_{i=1}^n \\hat{P}(w_i | real)$ and $\\prod_{i=1}^n \\hat{P}(w_i | fake)$ invloves computing products of a lot of really small numbers (which might result in underflow), the property that $a_1, a_2, ..., a_n = exp(log a_1 + log a_2 + ... + log a_n)$ was used to compute the product.\n",
    "\n",
    "The values of $m$ and $\\hat{p}$ were determined using random search over the performance of validation set.\n",
    "\n",
    "$m$ is the number of examples to be included in the prior calculation. The more number of examples, the more $\\hat{p}$ influences the final probability calculation. Values of $m$ were tried on a logarithmic scale of $1, 10, 100, 1000$. Out of these, $m = 1$ gave the best result.\n",
    "\n",
    "$\\hat{p}$ is the prior probability of the word being real or fake. Values of $\\hat{p}$ were tried in $0.1, 0.5, 0.7, 1$. Out of these $\\hat{p} = 1$ gave the best performance.\n",
    "\n",
    "Note: $\\hat{p}$ was used as prior in calculation for both word being real and fake. This finding (low $m$ and $\\hat{p}$) seems to imply that our prior assumptions in this case are not very accurate and it was best to have prior influence as minimal as possible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also wanted to test what happened if i use nltk.steam library for stem words.But accuracy decraeses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_test1 = pd.read_csv(\"test.csv\",sep=\",\",error_bad_lines=False)\n",
    "news_test1.columns = [\"Id\",\"Category\" ]\n",
    "news_test = news_test1[\"Id\"]\n",
    "new_test_realval = news_test1[\"Category\"]\n",
    "news_test = list(news_test)\n",
    "steamtest = list()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "for i in news_test:\n",
    "    i = i.split(\"\\n\")\n",
    "    i = i[0].split(\" \")\n",
    "    new_sentence = \"\"\n",
    "    for m in i:\n",
    "        #m = ps.stem(m)\n",
    "        new_sentence+=m+\" \"\n",
    "    steamtest.append(new_sentence)\n",
    "\n",
    "news_test = steamtest\n",
    "\n",
    "x = news_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each headline the code computes p(headline $\\mid$ class), so for all words in training set, add up log(word count) if the word is present in headline, otherwise add log(1 - word count). And finally compute exp of that sum, the result can then be used to compute p(class $\\mid$ headline).But we are training data is too small so we are using log function too. I append \"123456789\" because of i can find which word is exist in real news and fake new but if the word does not exist in real headlines and fake headlines my algorithm can not add this word to vector of sentence so lenght is smaller and accuracy is influenced by these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Real :  0.602448685631977\n",
      "Prior Fake :  0.39755131436802305\n"
     ]
    }
   ],
   "source": [
    "real_all_words_list = real_all_words.split(\" \")\n",
    "fake_all_words_list = fake_all_words.split(\" \")\n",
    "\n",
    "merged_list = list(set().union(real_all_words_list, fake_all_words_list))\n",
    "\n",
    "prob_fake = list()\n",
    "prob_real = list()\n",
    "\n",
    "#probability for this class\n",
    "\n",
    "prob_class_real = real_news_size/(real_news_size+fake_news_size)\n",
    "prob_class_fake = fake_news_size/(real_news_size+fake_news_size)\n",
    "\n",
    "print(\"Prior Real : \",prob_class_real)\n",
    "print(\"Prior Fake : \",prob_class_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used CountVectorizer and transform the test headlines matrix in this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_real = real_news_vec.transform(news_test)\n",
    "real_vec = vector_real.toarray()\n",
    "\n",
    "news_test_d = news_test\n",
    "count_d = 0\n",
    "indexes_test_real = list()\n",
    "\n",
    "#Getting word indexes in real training headlines\n",
    "\n",
    "for d in real_vec:\n",
    "    indexes = [i for i, j in enumerate(d) if j == 1]\n",
    "    if (len(indexes) < len(news_test_d[count_d].split(\" \"))):\n",
    "        x = len(news_test_d[count_d].split(\" \")) - len(indexes)\n",
    "        for i in range(x):\n",
    "            indexes.append(123456789)\n",
    "    count_d += 1\n",
    "    indexes_test_real.append(indexes)\n",
    "\n",
    "real_unique_words_size = len(real_news_vec.vocabulary_)\n",
    "realcount_all_and_uniques = len(merged_list) + real_news_size\n",
    "\n",
    "#Calculate the probability of that headlines for real headlines\n",
    "for i in indexes_test_real:\n",
    "    probability_real = 0\n",
    "    for index in i:\n",
    "        try:\n",
    "            count_word = (bag_of_words_real.toarray()[0][index] + 1)\n",
    "        except(IndexError):\n",
    "            count_word = (1)\n",
    "        probability_real += math.log10(count_word / realcount_all_and_uniques)\n",
    "    probability_real += math.log10(prob_class_real)\n",
    "    prob_real.append((probability_real))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do same things for calculate fake news headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test for fake unigram\n",
    "\n",
    "vector_fake = fake_news_vec.transform(news_test)\n",
    "fake_vec = vector_fake.toarray()\n",
    "\n",
    "news_test_e = news_test\n",
    "count_e = 0\n",
    "indexes_test_fake = list()\n",
    "\n",
    "for d in fake_vec:\n",
    "    indexes = [i for i, j in enumerate(d) if j == 1]\n",
    "    if(len(indexes) < len(news_test_e[count_e].split(\" \"))):\n",
    "        x  = len(news_test_e[count_e].split(\" \")) - len(indexes)\n",
    "        for i in range(x):\n",
    "            indexes.append(123456789)\n",
    "    count_e+=1\n",
    "    indexes_test_fake.append(indexes)\n",
    "\n",
    "fake_unique_words_size = len(fake_news_vec.vocabulary_)\n",
    "fakecount_all_and_uniques = len(merged_list) + fake_news_size\n",
    "\n",
    "for i in indexes_test_fake:\n",
    "    probability_fake = 0\n",
    "    for index in i:\n",
    "        try:\n",
    "            count_word = (bag_of_words_fake.toarray()[0][index] + 1)\n",
    "        except(IndexError):\n",
    "            count_word = (1)\n",
    "        probability_fake+=math.log10(count_word/fakecount_all_and_uniques)\n",
    "    probability_fake += math.log10(prob_class_fake)\n",
    "    prob_fake.append((probability_fake))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate probabilities headlines is fake or real.Then i calculated the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(real_test,fake_test,realvalues):\n",
    "    test_list = list()\n",
    "    for i in range(len(real_test)):\n",
    "        if (fake_test[i] > real_test[i]):\n",
    "            test_list.append(0)\n",
    "        else:\n",
    "            test_list.append(1)\n",
    "\n",
    "    test_real_list = list()\n",
    "    for i in realvalues:\n",
    "        if(i == \"fake\"):\n",
    "            test_real_list.append(0)\n",
    "        else:\n",
    "            test_real_list.append(1)\n",
    "\n",
    "    true_ = 0\n",
    "    for i in range(len(test_real_list)):\n",
    "        if(test_real_list[i] == test_list[i]):\n",
    "            true_+=1\n",
    "\n",
    "    print(\"accuracy naive bayes : \",100*true_/len(test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram\n",
      "accuracy naive bayes :  85.88957055214723\n"
     ]
    }
   ],
   "source": [
    "print(\"Unigram\")\n",
    "test(prob_real,prob_fake,new_test_realval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some English words occur together more frequently. For example - Sky High, do or die, best performance, heavy rain etc. So, in a text document we may need to identify such pair of words which will help in sentiment analysis. First, we need to generate such word pairs from the existing sentence maintain their current sequences. Such pairs are called bigrams. Python has a bigram function as part of these bigram function which helps us generate these pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram(bi_news_list,newtest,prob_class_bi):\n",
    "\n",
    "    prob_bi = list()\n",
    "\n",
    "    bi_news_vec = CountVectorizer(ngram_range=(2,2), max_df=1.0, min_df=1, max_features=None)\n",
    "    bi_news_train = bi_news_vec.fit(bi_news_list)\n",
    "    bi_bag_of_words = bi_news_vec.transform(bi_news_list)\n",
    "\n",
    "    test_dtm = bi_news_train.transform(newtest)\n",
    "\n",
    "    listOfBigrams = list()\n",
    "    for m in news_test:\n",
    "        m=m.split(\" \")\n",
    "        lenght_test = len(m)\n",
    "        otherlist = list()\n",
    "        for i in range(lenght_test):\n",
    "            if i < lenght_test - 1:\n",
    "                otherlist.append((m[i]+\" \"+m[i + 1]))\n",
    "\n",
    "        listOfBigrams.append(otherlist)\n",
    "\n",
    "    bi_unique_words_size = len(bi_news_vec.vocabulary_)\n",
    "    bicount_all_and_uniques = (bi_bag_of_words.shape[1]) + bi_unique_words_size\n",
    "    mylist = [sum(x) for x in zip(*(bi_bag_of_words.toarray()))]\n",
    "\n",
    "    for sentence in listOfBigrams:\n",
    "        probability_bi = 0\n",
    "        for i in sentence:\n",
    "            if(bi_news_train.vocabulary_.get(i)!=None):\n",
    "                count_word = (mylist[bi_news_train.vocabulary_.get(i)] + 1)\n",
    "            else:\n",
    "                count_word = (1)\n",
    "            probability_bi += math.log10(count_word / bicount_all_and_uniques)\n",
    "        probability_bi += math.log10(prob_class_bi)\n",
    "        prob_bi.append((probability_bi))\n",
    "\n",
    "    return prob_bi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram accuracy naive bayes \n",
      "accuracy naive bayes :  82.82208588957056\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bifake_news_list = list()\n",
    "for binews in bifake_news_file:\n",
    "    binews = binews.split(\"\\n\")\n",
    "    bifake_news_list.append(binews[0])\n",
    "\n",
    "bireal_news_list = list()\n",
    "for binewsx in bireal_news_file:\n",
    "    binewsx = binewsx.split(\"\\n\")\n",
    "    bireal_news_list.append(binewsx[0])\n",
    "\n",
    "prob_class_bireal = len(bireal_news_list)/(len(bireal_news_list)+len(bifake_news_list))\n",
    "prob_class_bifake = len(bifake_news_list)/(len(bireal_news_list)+len(bifake_news_list))\n",
    "\n",
    "bifakelist = bigram(bifake_news_list,news_test,prob_class_bifake)\n",
    "bireallist = bigram(bireal_news_list,news_test,prob_class_bireal)\n",
    "\n",
    "print(\"Bigram accuracy naive bayes \")\n",
    "test(bireallist,bifakelist,new_test_realval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities were calculated as follows: \n",
    "\n",
    "\\begin{equation*}\n",
    "\tP(class) = \\frac{\\text{\\# of headlines of that class}}{\\text{total \\# of headlines}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\tP(word | class) = \\frac{\\text{ \\# of occurrences of word in headlines of that class}}{\\text{total number of headlines of that class}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(class | word) = \\frac{P(word | class) * P(class)} { ( P(word|fake) * P(fake) + P(word|real) *P(real) }\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{align*}\n",
    "\tP(class | \\neg word) = \\frac{P(\\neg word | class)P(class)}{P(\\neg word)}\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\tP(\\neg word | class) = 1 - P(word | class)\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "\tP(\\neg word) = \\frac{\\text{headlines without word}}{\\# \\text{headlines}}\n",
    "\\end{equation*}\n",
    "\n",
    "The values of $P(class|word)$ are generally much larger than those of $P(class| \\neg words)$. Thus, the presence of words seem like stronger predictors of whether a headline is real or fake than absence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the above 4 lists, I calculated p(class$|$word) or p(class$|$!word) and select the top 10 words with the highest probability in each category. We can also see that the top 10 in p(fake$|$word) and p(real$|$!word) have the same words (but different probabilities). This makes sense as the words that most strongly indicate the headline is fake are the ones their absence most strongly indicates the headline is real. We can also notice that some words presence have a bigger effect on classifying headline than the effect of words being absent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def presence_absence(all_words_fake,all_words_real,remove_stop_words):\n",
    "\n",
    "    real_words = Counter()\n",
    "    all_words_real_1 = all_words_real\n",
    "    real_words.update(all_words_real_1.split())\n",
    "\n",
    "    fake_words = Counter()\n",
    "    all_words_fake_1 = all_words_fake\n",
    "    fake_words.update(all_words_fake_1.split())\n",
    "\n",
    "    keywords = list((all_words_fake.split(\" \")+all_words_real.split(\" \")))\n",
    "    keywords_2 = \" \".join(str(x) for x in keywords)\n",
    "    keywords_1 = Counter()\n",
    "    keywords_1.update(keywords_2.split(\" \"))\n",
    "\n",
    "    if(remove_stop_words):\n",
    "        keywords = list(set(keywords) - set(ENGLISH_STOP_WORDS))\n",
    "    num_real_words = len(real_all_words)\n",
    "    num_fake_words = len(fake_all_words)\n",
    "    num_words_training = num_fake_words + num_real_words\n",
    "\n",
    "    # class probabilities\n",
    "    prob_class_fake = num_fake_words / num_words_training\n",
    "    prob_class_real = num_real_words / num_words_training\n",
    "\n",
    "    prob_real_ = {}\n",
    "    prob_fake_ = {}\n",
    "\n",
    "    notp_real_ = {}\n",
    "    notp_fake_ = {}\n",
    "\n",
    "\n",
    "    for word in keywords:\n",
    "\n",
    "        if(real_words.get(word) !=None and fake_words.get(word) != None):\n",
    "\n",
    "            p_word_given_real = real_words.get(word)/num_real_words\n",
    "            p_word_given_fake = fake_words.get(word)/num_fake_words\n",
    "\n",
    "            prob_word = np.exp(np.sum(np.log([p_word_given_real, prob_class_real]))) + np.exp(np.sum(np.log([p_word_given_fake, prob_class_fake])))\n",
    "\n",
    "            prob_real_[word] = np.exp(np.sum(np.log([p_word_given_real, prob_class_real]))) / prob_word\n",
    "            prob_fake_[word] = np.exp(np.sum(np.log([p_word_given_fake, prob_class_fake]))) / prob_word\n",
    "\n",
    "            notprobword = 1-prob_word\n",
    "            notp_real_[word] = np.exp(np.sum(np.log([(1 - p_word_given_real), prob_class_real]))) / (notprobword)\n",
    "            notp_fake_[word] = np.exp(np.sum(np.log([(1 - p_word_given_fake), prob_class_fake]))) / (notprobword)\n",
    "\n",
    "        elif(real_words.get(word) == None and fake_words.get(word) != None ):\n",
    "\n",
    "            p_word_given_fake = fake_words.get(word) / num_fake_words\n",
    "            prob_word =  np.exp(np.sum(np.log([p_word_given_fake, prob_class_fake])))\n",
    "            notprobword = 1 - prob_word\n",
    "            prob_fake_[word] = np.exp(np.sum(np.log([p_word_given_fake, prob_class_fake]))) / prob_word\n",
    "            notp_fake_[word] = np.exp(np.sum(np.log([(1 - p_word_given_fake), prob_class_fake]))) / (notprobword)\n",
    "\n",
    "        elif(fake_words.get(word) == None and real_words.get(word) != None ):\n",
    "\n",
    "            p_word_given_real = real_words.get(word) / num_real_words\n",
    "            prob_word = np.exp(np.sum(np.log([p_word_given_real, prob_class_real])))\n",
    "\n",
    "            notprobword = 1 - prob_word\n",
    "\n",
    "            prob_real_[word] = np.exp(np.sum(np.log([p_word_given_real, prob_class_real]))) / prob_word\n",
    "            notp_real_[word] = np.exp(np.sum(np.log([(1 - p_word_given_real), prob_class_real]))) / (notprobword)\n",
    "\n",
    "    presence_real = list()\n",
    "    for i,v in sorted(prob_real_.items(),key=operator.itemgetter(1), reverse=True):\n",
    "        presence_real.append(i)\n",
    "    presence_fake = list()\n",
    "    for i,v in sorted(prob_fake_.items(),key=operator.itemgetter(1), reverse=True):\n",
    "        presence_fake.append(i)\n",
    "\n",
    "    absence_real = list()\n",
    "    for i,v in sorted(notp_real_.items(),key=operator.itemgetter(1), reverse=True):\n",
    "        absence_real.append(i)\n",
    "\n",
    "    absence_fake = list()\n",
    "    for i,v in sorted(notp_fake_.items(),key=operator.itemgetter(1), reverse=True):\n",
    "        absence_fake.append(i)\n",
    "    \n",
    "    print(\"Presence Real:\\n P(real|word)\")\n",
    "    count = 0\n",
    "    for i in presence_real[:10]:\n",
    "        print(\"\\t\",count,\"-\",i)\n",
    "        count+=1\n",
    "    print(\"\\nPresence Fake:\\n P(fake|word)\")\n",
    "    count = 0\n",
    "    for i in presence_fake[:10]:\n",
    "        print(\"\\t\",count,\"-\",i)\n",
    "        count+=1\n",
    "    print(\"\\nAbsence Real:\\n P(real|-word)\")\n",
    "    count = 0\n",
    "    for i in absence_real[:10]:\n",
    "        print(\"\\t\",count,\"-\",i)\n",
    "        count+=1\n",
    "        \n",
    "    print(\"\\nAbsence Fake:\\n P(fake|-word)\")\n",
    "    count = 0\n",
    "    for i in absence_fake[:10]:\n",
    "        print(\"\\t\",count,\"-\",i)\n",
    "        count+=1\n",
    "         \n",
    "        \n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presence Real:\n",
      " P(real|word)\n",
      "\t 0 - charlottesville\n",
      "\t 1 - praised\n",
      "\t 2 - based\n",
      "\t 3 - australias\n",
      "\t 4 - range\n",
      "\t 5 - disasters\n",
      "\t 6 - eslake\n",
      "\t 7 - shake\n",
      "\t 8 - australia\n",
      "\t 9 - refugee\n",
      "\n",
      "Presence Fake:\n",
      " P(fake|word)\n",
      "\t 0 - flipping\n",
      "\t 1 - machines\n",
      "\t 2 - populism\n",
      "\t 3 - controlled\n",
      "\t 4 - bollywood\n",
      "\t 5 - ad\n",
      "\t 6 - meant\n",
      "\t 7 - sway\n",
      "\t 8 - indian\n",
      "\t 9 - hilarious\n",
      "\n",
      "Absence Real:\n",
      " P(real|-word)\n",
      "\t 0 - the\n",
      "\t 1 - hillary\n",
      "\t 2 - a\n",
      "\t 3 - is\n",
      "\t 4 - and\n",
      "\t 5 - just\n",
      "\t 6 - clinton\n",
      "\t 7 - you\n",
      "\t 8 - of\n",
      "\t 9 - for\n",
      "\n",
      "Absence Fake:\n",
      " P(fake|-word)\n",
      "\t 0 - donald\n",
      "\t 1 - trump\n",
      "\t 2 - trumps\n",
      "\t 3 - us\n",
      "\t 4 - says\n",
      "\t 5 - north\n",
      "\t 6 - ban\n",
      "\t 7 - wall\n",
      "\t 8 - deal\n",
      "\t 9 - comments\n"
     ]
    }
   ],
   "source": [
    "presence_absence(fake_all_words,real_all_words,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stop words\n",
      "Presence Real:\n",
      " P(real|word)\n",
      "\t 0 - schoolboy\n",
      "\t 1 - trudeau\n",
      "\t 2 - wedge\n",
      "\t 3 - speaks\n",
      "\t 4 - leaving\n",
      "\t 5 - lobbyist\n",
      "\t 6 - uhlmann\n",
      "\t 7 - rebound\n",
      "\t 8 - unlawfully\n",
      "\t 9 - struggled\n",
      "\n",
      "Presence Fake:\n",
      " P(fake|word)\n",
      "\t 0 - gambling\n",
      "\t 1 - loan\n",
      "\t 2 - display\n",
      "\t 3 - heroic\n",
      "\t 4 - suepennontwitte\n",
      "\t 5 - trumpprotest\n",
      "\t 6 - camp\n",
      "\t 7 - domino\n",
      "\t 8 - generals\n",
      "\t 9 - humiliate\n",
      "\n",
      "Absence Real:\n",
      " P(real|-word)\n",
      "\t 0 - hillary\n",
      "\t 1 - just\n",
      "\t 2 - clinton\n",
      "\t 3 - black\n",
      "\t 4 - watch\n",
      "\t 5 - america\n",
      "\t 6 - comment\n",
      "\t 7 - obama\n",
      "\t 8 - win\n",
      "\t 9 - new\n",
      "\n",
      "Absence Fake:\n",
      " P(fake|-word)\n",
      "\t 0 - donald\n",
      "\t 1 - trump\n",
      "\t 2 - trumps\n",
      "\t 3 - says\n",
      "\t 4 - north\n",
      "\t 5 - ban\n",
      "\t 6 - wall\n",
      "\t 7 - deal\n",
      "\t 8 - trade\n",
      "\t 9 - comments\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "print(\"With stop words\")\n",
    "presence_absence(fake_all_words,real_all_words,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of $P(class|word)$ are generally much larger than those of $P(class| \\neg words)$. Thus, the presence of words seem like stronger predictors of whether a headline is real or fake than absence. \n",
    "\n",
    " \n",
    "Since the top ten words listed do not contain any stop-words, the list remains unchanged upon removing stop words.  \n",
    "\n",
    " \n",
    "Stop words are not helpful when headlines are being assessed for their content, but are important for context. For example,  the phase \"trump can't think\" and the phrase \"trump can think\" reduce to \"trump think\" if we remove the stop words, (cant, can). The reduced phrase tell us what the sentence is about but do not convey the original message of each sentence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In unigram we just count the word how many time appear in headlines without looking previous word but in bigram we are checking the words two by two.We are trying to teach machine how to do natural language processing. We human can understand language easily but machines cannot so we trying to teach them specific pattern of language. As specific word has meaning but when we combine the words(i.e group of words) than it will be more helpful to understand the meaning.\n",
    "\n",
    "n-gram is basically set of occurring words within given window so when\n",
    "\n",
    "n=1 it is Unigram\n",
    "n=2 it is bigram\n",
    "n=3 it is trigram and so on\n",
    "Now suppose machine try to understand the meaning of sentence \"I have a lovely dog\" than it will split sentences into specific chunk.\n",
    "\n",
    "It will consider word one by one which is unigram so each word will be a gram.\n",
    "\n",
    "\"I\", \"have\", \"a\" , \"lovely\" , \"dog\"\n",
    "I will consider two word at a time so it will be biagram so each two adjacent words will be biagram\n",
    "\n",
    "\"I have\" , \"have a\" , \"a lovely\" , \"lovely dog\"\n",
    "So like this machine will split sentences into small group of words to understand its meaning\n",
    "\n",
    "\n",
    "## Resources\n",
    "\n",
    "http://nowak.ece.wisc.edu/bigram.pdf\n",
    "ftp://www.cs.toronto.edu/pub/radford/bayes-tut.pdf\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
